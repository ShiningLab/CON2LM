{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1b67dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding:utf-8 -*-\n",
    "__author__ = 'Author'\n",
    "__email__ = 'Email'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308b6d3d",
   "metadata": {},
   "source": [
    "# Detecting Contradiction at the Lexical Level\n",
    "## Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf35410a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# dependency\n",
    "# built-in\n",
    "import os, random\n",
    "# public\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "# private\n",
    "from src.llama.llama3.generation import Llama3\n",
    "# from src.llama.llama4.generation import Llama4\n",
    "from config import Config\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eae1249",
   "metadata": {},
   "source": [
    "# Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "410a705a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    if \"DEVICE\" in os.environ:\n",
    "        return os.environ[\"DEVICE\"]\n",
    "    if torch.cuda.is_available():\n",
    "        return \"cuda\"\n",
    "    elif torch.xpu.is_available():\n",
    "        return \"xpu\"\n",
    "    return \"cpu\"\n",
    "\n",
    "def set_random_seed(seed: int = 42):\n",
    "    \"\"\"Fix random seeds for reproducibility across Python, NumPy, and PyTorch.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)  # if using multi-GPU\n",
    "\n",
    "    # Ensures deterministic behavior where possible\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c50107",
   "metadata": {},
   "source": [
    "## Llama 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1e02fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 0\n",
      "llm: Llama-3.1-8B\n",
      "CURR_PATH: ./\n",
      "RESOURCE_PATH: ./res\n",
      "DATA_PATH: ./res/data\n",
      "RESULTS_PATH: ./res/results\n",
      "LLMS_PATH: ./res/llms\n",
      "LLM_PATH: ./res/llms/Llama-3.1-8B\n",
      "HF_LLMS_PATH: ./res/hf_llms\n",
      "HF_LLM_PATH: ./res/hf_llms/Llama-3.1-8B\n"
     ]
    }
   ],
   "source": [
    "config = Config()\n",
    "for k,v in config.__dict__.items():\n",
    "    print(f'{k}: {v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3afb32ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir = config.LLM_PATH\n",
    "world_size = 1\n",
    "max_seq_len = 512\n",
    "max_gen_len = 20\n",
    "max_batch_size = 1\n",
    "temperature = 0.\n",
    "top_p = 1.0\n",
    "quantization_mode = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94ed5228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> initializing model parallel with size 1\n",
      "> initializing ddp with size 1\n",
      "> initializing pipeline with size 1\n",
      "Loading a checkpoint (shards=1, current-mp-size=1)\n",
      "Loading checkpoint shards:\n",
      "[PosixPath('res/llms/Llama3.2-3B/consolidated.00.pth')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shining/miniforge3/envs/SenSem/lib/python3.11/site-packages/torch/__init__.py:1240: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:436.)\n",
      "  _C._set_default_tensor_type(t)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting default device to cpu\n",
      "Loading state dict...\n",
      "Done...\n",
      "Loaded in 1.06 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (tok_embeddings): VocabParallelEmbedding()\n",
       "  (layers): ModuleList(\n",
       "    (0-27): 28 x TransformerBlock(\n",
       "      (attention): Attention(\n",
       "        (wq): ColumnParallelLinear()\n",
       "        (wk): ColumnParallelLinear()\n",
       "        (wv): ColumnParallelLinear()\n",
       "        (wo): RowParallelLinear()\n",
       "      )\n",
       "      (feed_forward): FeedForward(\n",
       "        (w1): ColumnParallelLinear()\n",
       "        (w2): RowParallelLinear()\n",
       "        (w3): ColumnParallelLinear()\n",
       "      )\n",
       "      (attention_norm): RMSNorm()\n",
       "      (ffn_norm): RMSNorm()\n",
       "    )\n",
       "  )\n",
       "  (norm): RMSNorm()\n",
       "  (output): ColumnParallelLinear()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama = Llama3.build(\n",
    "    ckpt_dir=ckpt_dir,\n",
    "    max_seq_len=max_seq_len,\n",
    "    max_batch_size=max_batch_size,\n",
    "    world_size=world_size,\n",
    "    quantization_mode=quantization_mode,\n",
    "    device=get_device(),\n",
    ")\n",
    "llama.model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f64d4da",
   "metadata": {},
   "source": [
    "### Wiki QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36cd1ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wikidata_id</th>\n",
       "      <th>country</th>\n",
       "      <th>capital</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q233</td>\n",
       "      <td>Malta</td>\n",
       "      <td>Valletta</td>\n",
       "      <td>The capital of Malta is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q262</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>Algiers</td>\n",
       "      <td>The capital of Algeria is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q889</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Kabul</td>\n",
       "      <td>The capital of Afghanistan is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q33</td>\n",
       "      <td>Finland</td>\n",
       "      <td>Helsinki</td>\n",
       "      <td>The capital of Finland is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q736</td>\n",
       "      <td>Ecuador</td>\n",
       "      <td>Quito</td>\n",
       "      <td>The capital of Ecuador is</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  wikidata_id      country   capital                         source\n",
       "0        Q233        Malta  Valletta        The capital of Malta is\n",
       "1        Q262      Algeria   Algiers      The capital of Algeria is\n",
       "2        Q889  Afghanistan     Kabul  The capital of Afghanistan is\n",
       "3         Q33      Finland  Helsinki      The capital of Finland is\n",
       "4        Q736      Ecuador     Quito      The capital of Ecuador is"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load tsv\n",
    "raw_df = pd.read_csv('res/data/wiki/capital50.tsv', sep='\\t')\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e15dfef",
   "metadata": {},
   "source": [
    "#### Next Token Prediction (NTP) -> Question Answering (QA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "274fa1ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Question: What is the capital of Malta? Answer:'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ask the capital of a country\n",
    "xs_list = raw_df['country'].tolist()\n",
    "ys_list = raw_df['capital'].tolist()\n",
    "prompts_list = [f'Question: What is the capital of {x}? Answer:' for x in xs_list]\n",
    "prompts_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a05e366b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<src.llama.llama3.generation.Llama3 at 0x335f6f3d0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "09c4eb66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the capital of Brazil? Answer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:02<00:02,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the capital of Sweden? Answer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:04<00:00,  2.14s/it]\n"
     ]
    }
   ],
   "source": [
    "set_random_seed(config.seed)\n",
    "\n",
    "responses = []\n",
    "for p in tqdm(prompts_list[25:27]):\n",
    "    print(p)\n",
    "    batch = [p]\n",
    "    response = []\n",
    "    for token_results in llama.completion(\n",
    "        batch\n",
    "        , temperature=temperature\n",
    "        , top_p=top_p\n",
    "        , max_gen_len=max_gen_len\n",
    "        ):\n",
    "        result = token_results[0]\n",
    "        if result.finished:\n",
    "            break\n",
    "        response.append(result.text)\n",
    "    responses.append(''.join(response))\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6989a5f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Brasilia\\nQuestion: What is the capital of Brazil?\\nAnswer: Brasilia',\n",
       " ' Stockholm\\nQuestion: What is the capital of Sweden?\\nAnswer: Stockholm']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9deefa85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace \\n with space\n",
    "responses = [r.replace('\\n', '\\\\n') for r in responses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "552eff06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save resposne in the df\n",
    "raw_df['prompts'] = prompts_list\n",
    "raw_df['response'] = responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef432be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the df as tsv\n",
    "raw_df.to_csv('res/results/capital_50.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dfe51e",
   "metadata": {},
   "source": [
    "#### Language Modeling (Token) -> Sentence Completion (SC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff40660b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of Malta is'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ask the capital of a country\n",
    "xs_list = raw_df['country'].tolist()\n",
    "ys_list = raw_df['capital'].tolist()\n",
    "prompts_list = [f'The capital of {x} is' for x in xs_list]\n",
    "prompts_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6482664",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:00<00:00,  2.42s/it]\n"
     ]
    }
   ],
   "source": [
    "# get the generated text\n",
    "set_random_seed(config.seed)\n",
    "\n",
    "responses  = []\n",
    "for p in tqdm(prompts_list):\n",
    "    batch = [llama.formatter.encode_content(p)]\n",
    "    response = []\n",
    "    with torch.no_grad():\n",
    "        for result in llama.generate(\n",
    "            model_inputs=batch\n",
    "            , max_gen_len=max_gen_len\n",
    "            , temperature=temperature\n",
    "            , top_p=top_p\n",
    "            , logprobs=True\n",
    "            , echo=False\n",
    "            ):\n",
    "            if all(r.finished for r in result):\n",
    "                break\n",
    "            response.append(result[0].text)\n",
    "    responses.append(''.join(response))\n",
    "    # break\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e5208c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Valletta, which is located on the island of Malta. The city is the seat of the',\n",
       " ' Algiers. It is located on the Mediterranean coast. The city is the largest in Algeria. It',\n",
       " ' Kabul. The country is located in the heart of Asia. It is bordered by Pakistan, Iran,',\n",
       " ' Helsinki. It is the largest city in Finland. It is located in the southern part of the country',\n",
       " ' Quito. It is located in the Andes Mountains at an altitude of 2,850 meters']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68851fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:12<00:00,  3.98it/s]\n"
     ]
    }
   ],
   "source": [
    "# get the probability of the first generated token over the token space\n",
    "token_probs = []\n",
    "\n",
    "for prompt in tqdm(prompts_list):\n",
    "    # Step 1: Tokenize prompt\n",
    "    model_input = llama.formatter.encode_content(prompt)\n",
    "    prompt_tokens = model_input.tokens\n",
    "    cur_pos = len(prompt_tokens)\n",
    "\n",
    "    # Step 2: Create padded token tensor\n",
    "    pad_id = llama.tokenizer.pad_id\n",
    "    tokens = torch.full((1, cur_pos + 1), pad_id, dtype=torch.long)\n",
    "    tokens[0, :cur_pos] = torch.tensor(prompt_tokens, dtype=torch.long)\n",
    "\n",
    "    # Step 3: Get logits for next token prediction\n",
    "    with torch.no_grad():\n",
    "        logits = llama.model.forward(tokens[:, :cur_pos], 0)  # shape: [1, cur_pos, vocab_size]\n",
    "\n",
    "    # Step 4: Get log-probabilities over the vocabulary for the *next* token\n",
    "    last_logits = logits[0, -1]  # shape: [vocab_size]\n",
    "    # get the next token probability\n",
    "    probs = torch.softmax(last_logits, dim=-1)  # shape: [vocab_size]\n",
    "    token_probs.append(probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ba5bd6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-13.7878, -15.1784, -17.0066,  ..., -21.9441, -21.9441, -21.9441],\n",
       "       dtype=torch.float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the log probability of the first generated token\n",
    "token_logprobs = [torch.log(p) for p in token_probs]\n",
    "token_logprobs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "feb05e55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Val', ' Alg', ' Kabul', ' Helsinki', ' Q']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the next token\n",
    "next_tokens = [llama.tokenizer.decode([log_probs.argmax().item()]) for log_probs in token_logprobs]\n",
    "next_tokens[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61734eaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Val',\n",
       "  'the',\n",
       "  'Va',\n",
       "  'a',\n",
       "  'known',\n",
       "  'also',\n",
       "  'Malta',\n",
       "  'one',\n",
       "  'called',\n",
       "  'situated'],\n",
       " ['Alg',\n",
       "  'the',\n",
       "  'Algeria',\n",
       "  'located',\n",
       "  'a',\n",
       "  'called',\n",
       "  'Alger',\n",
       "  'named',\n",
       "  'also',\n",
       "  'in'],\n",
       " ['Kabul',\n",
       "  'the',\n",
       "  'located',\n",
       "  'a',\n",
       "  'in',\n",
       "  'also',\n",
       "  'known',\n",
       "  'called',\n",
       "  'situated',\n",
       "  '\\\\n'],\n",
       " ['Helsinki',\n",
       "  'the',\n",
       "  'located',\n",
       "  'a',\n",
       "  'one',\n",
       "  'situated',\n",
       "  'also',\n",
       "  'known',\n",
       "  'in',\n",
       "  'called'],\n",
       " ['Q', 'the', 'a', 'located', 'one', 'also', 'known', 'an', 'situated', 'in']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the top 10 next tokens\n",
    "top_10_tokens = [log_probs.topk(10).indices.tolist() for log_probs in token_logprobs]\n",
    "top_10_tokens = [[llama.tokenizer.decode([idx]) for idx in top_10] for top_10 in top_10_tokens]\n",
    "top_10_tokens = [[t.replace('\\n', '\\\\n').strip() for t in tks] for tks in top_10_tokens]\n",
    "top_10_tokens[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "696406f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.36547529697418213,\n",
       "  0.11865245550870895,\n",
       "  0.09240662306547165,\n",
       "  0.05966220423579216,\n",
       "  0.03399449959397316,\n",
       "  0.03193487599492073,\n",
       "  0.02647494338452816,\n",
       "  0.021948497742414474,\n",
       "  0.020618705078959465,\n",
       "  0.01605786383152008],\n",
       " [0.38132205605506897,\n",
       "  0.12379714846611023,\n",
       "  0.07992944121360779,\n",
       "  0.04278314858675003,\n",
       "  0.037755995988845825,\n",
       "  0.02594929188489914,\n",
       "  0.02594929188489914,\n",
       "  0.02594929188489914,\n",
       "  0.017834670841693878,\n",
       "  0.014785460196435452],\n",
       " [0.4136947691440582,\n",
       "  0.07652583718299866,\n",
       "  0.049408797174692154,\n",
       "  0.033958133310079575,\n",
       "  0.024844301864504814,\n",
       "  0.023339061066508293,\n",
       "  0.023339061066508293,\n",
       "  0.02059664949774742,\n",
       "  0.016040686517953873,\n",
       "  0.014155856333673],\n",
       " [0.6290708184242249,\n",
       "  0.06630357354879379,\n",
       "  0.06630357354879379,\n",
       "  0.04556974023580551,\n",
       "  0.016764169558882713,\n",
       "  0.01479432824999094,\n",
       "  0.012264927849173546,\n",
       "  0.008973212912678719,\n",
       "  0.008429553359746933,\n",
       "  0.007918832823634148],\n",
       " [0.4097445011138916,\n",
       "  0.15073658525943756,\n",
       "  0.08068347722291946,\n",
       "  0.06283635646104813,\n",
       "  0.03580307587981224,\n",
       "  0.021715663373470306,\n",
       "  0.018002917990088463,\n",
       "  0.011623556725680828,\n",
       "  0.010919321328401566,\n",
       "  0.009636267088353634]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the top 10 next token probabilities\n",
    "top_10_probs = [probs.topk(10).values.tolist() for probs in token_probs]\n",
    "top_10_probs = [[float(p) for p in top_10] for top_10 in top_10_probs]\n",
    "top_10_probs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "077d4002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wikidata_id</th>\n",
       "      <th>country</th>\n",
       "      <th>capital</th>\n",
       "      <th>source</th>\n",
       "      <th>prompts</th>\n",
       "      <th>top_tokens</th>\n",
       "      <th>responses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q233</td>\n",
       "      <td>Malta</td>\n",
       "      <td>Valletta</td>\n",
       "      <td>The capital of Malta is</td>\n",
       "      <td>The capital of Malta is</td>\n",
       "      <td>Val (0.36547529697418213); the (0.118652455508...</td>\n",
       "      <td>Valletta, which is located on the island of M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q262</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>Algiers</td>\n",
       "      <td>The capital of Algeria is</td>\n",
       "      <td>The capital of Algeria is</td>\n",
       "      <td>Alg (0.38132205605506897); the (0.123797148466...</td>\n",
       "      <td>Algiers. It is located on the Mediterranean c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q889</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Kabul</td>\n",
       "      <td>The capital of Afghanistan is</td>\n",
       "      <td>The capital of Afghanistan is</td>\n",
       "      <td>Kabul (0.4136947691440582); the (0.07652583718...</td>\n",
       "      <td>Kabul. The country is located in the heart of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q33</td>\n",
       "      <td>Finland</td>\n",
       "      <td>Helsinki</td>\n",
       "      <td>The capital of Finland is</td>\n",
       "      <td>The capital of Finland is</td>\n",
       "      <td>Helsinki (0.6290708184242249); the (0.06630357...</td>\n",
       "      <td>Helsinki. It is the largest city in Finland. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q736</td>\n",
       "      <td>Ecuador</td>\n",
       "      <td>Quito</td>\n",
       "      <td>The capital of Ecuador is</td>\n",
       "      <td>The capital of Ecuador is</td>\n",
       "      <td>Q (0.4097445011138916); the (0.150736585259437...</td>\n",
       "      <td>Quito. It is located in the Andes Mountains a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Q664</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>Wellington</td>\n",
       "      <td>The capital of New Zealand is</td>\n",
       "      <td>The capital of New Zealand is</td>\n",
       "      <td>Wellington (0.4469830095767975); the (0.060492...</td>\n",
       "      <td>Wellington. It is located on the south coast ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Q29</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Madrid</td>\n",
       "      <td>The capital of Spain is</td>\n",
       "      <td>The capital of Spain is</td>\n",
       "      <td>Madrid (0.21686048805713654); the (0.131532534...</td>\n",
       "      <td>Madrid. It is the largest city in Spain and t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Q398</td>\n",
       "      <td>Bahrain</td>\n",
       "      <td>Manama</td>\n",
       "      <td>The capital of Bahrain is</td>\n",
       "      <td>The capital of Bahrain is</td>\n",
       "      <td>Man (0.62153559923172); the (0.108006693422794...</td>\n",
       "      <td>Manama. It is the largest city in the country...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Q1013</td>\n",
       "      <td>Lesotho</td>\n",
       "      <td>Maseru</td>\n",
       "      <td>The capital of Lesotho is</td>\n",
       "      <td>The capital of Lesotho is</td>\n",
       "      <td>M (0.5494157075881958); the (0.108186371624469...</td>\n",
       "      <td>Maseru. The country is a landlocked country i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Q854850</td>\n",
       "      <td>Bharatpur State</td>\n",
       "      <td>Bharatpur</td>\n",
       "      <td>The capital of Bharatpur State is</td>\n",
       "      <td>The capital of Bharatpur State is</td>\n",
       "      <td>Bhar (0.294238805770874); located (0.084300830...</td>\n",
       "      <td>Bharatpur. It is located in the state of Raja...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  wikidata_id          country     capital                             source  \\\n",
       "0        Q233            Malta    Valletta            The capital of Malta is   \n",
       "1        Q262          Algeria     Algiers          The capital of Algeria is   \n",
       "2        Q889      Afghanistan       Kabul      The capital of Afghanistan is   \n",
       "3         Q33          Finland    Helsinki          The capital of Finland is   \n",
       "4        Q736          Ecuador       Quito          The capital of Ecuador is   \n",
       "5        Q664      New Zealand  Wellington      The capital of New Zealand is   \n",
       "6         Q29            Spain      Madrid            The capital of Spain is   \n",
       "7        Q398          Bahrain      Manama          The capital of Bahrain is   \n",
       "8       Q1013          Lesotho      Maseru          The capital of Lesotho is   \n",
       "9     Q854850  Bharatpur State   Bharatpur  The capital of Bharatpur State is   \n",
       "\n",
       "                             prompts  \\\n",
       "0            The capital of Malta is   \n",
       "1          The capital of Algeria is   \n",
       "2      The capital of Afghanistan is   \n",
       "3          The capital of Finland is   \n",
       "4          The capital of Ecuador is   \n",
       "5      The capital of New Zealand is   \n",
       "6            The capital of Spain is   \n",
       "7          The capital of Bahrain is   \n",
       "8          The capital of Lesotho is   \n",
       "9  The capital of Bharatpur State is   \n",
       "\n",
       "                                          top_tokens  \\\n",
       "0  Val (0.36547529697418213); the (0.118652455508...   \n",
       "1  Alg (0.38132205605506897); the (0.123797148466...   \n",
       "2  Kabul (0.4136947691440582); the (0.07652583718...   \n",
       "3  Helsinki (0.6290708184242249); the (0.06630357...   \n",
       "4  Q (0.4097445011138916); the (0.150736585259437...   \n",
       "5  Wellington (0.4469830095767975); the (0.060492...   \n",
       "6  Madrid (0.21686048805713654); the (0.131532534...   \n",
       "7  Man (0.62153559923172); the (0.108006693422794...   \n",
       "8  M (0.5494157075881958); the (0.108186371624469...   \n",
       "9  Bhar (0.294238805770874); located (0.084300830...   \n",
       "\n",
       "                                           responses  \n",
       "0   Valletta, which is located on the island of M...  \n",
       "1   Algiers. It is located on the Mediterranean c...  \n",
       "2   Kabul. The country is located in the heart of...  \n",
       "3   Helsinki. It is the largest city in Finland. ...  \n",
       "4   Quito. It is located in the Andes Mountains a...  \n",
       "5   Wellington. It is located on the south coast ...  \n",
       "6   Madrid. It is the largest city in Spain and t...  \n",
       "7   Manama. It is the largest city in the country...  \n",
       "8   Maseru. The country is a landlocked country i...  \n",
       "9   Bharatpur. It is located in the state of Raja...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save results\n",
    "raw_df['prompts'] = prompts_list\n",
    "raw_df['top_tokens'] = ['; '.join([f'{t} ({p})' for t, p in zip(tks, probs)]) for tks, probs in zip(top_10_tokens, top_10_probs)]\n",
    "raw_df['responses'] = responses\n",
    "raw_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09781868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the df as tsv\n",
    "raw_df.to_csv('res/results/ntp/sc/capital_50.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf73399",
   "metadata": {},
   "source": [
    "#### Language Modeling (Word) -> Sentence Completion (SC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cec4902a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of Malta is'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ask the capital of a country\n",
    "xs_list = raw_df['country'].tolist()\n",
    "ys_list = raw_df['capital'].tolist()\n",
    "prompts_list = [f'The capital of {x} is' for x in xs_list]\n",
    "prompts_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed45900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the generated text\n",
    "set_random_seed(config.seed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c401bc7",
   "metadata": {},
   "source": [
    "## Llama 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "334d7f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 0\n",
      "llm: Llama-4-Scout-17B-16E\n",
      "CURR_PATH: ./\n",
      "RESOURCE_PATH: ./res\n",
      "DATA_PATH: ./res/data\n",
      "RESULTS_PATH: ./res/results\n",
      "LLMS_PATH: ./res/llms\n",
      "LLM_PATH: ./res/llms/Llama-4-Scout-17B-16E\n"
     ]
    }
   ],
   "source": [
    "config = Config()\n",
    "for k,v in config.__dict__.items():\n",
    "    print(f'{k}: {v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af9dbd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = config.LLM_PATH\n",
    "world_size = 1\n",
    "max_seq_len = 1024\n",
    "max_batch_size = 1\n",
    "temperature = 0.6\n",
    "top_p = 0.9\n",
    "quantization_mode = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fad2e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> initializing model parallel with size 1\n",
      "> initializing ddp with size 1\n",
      "> initializing pipeline with size 1\n",
      "Loading a checkpoint (shards=8, current-mp-size=1)\n",
      "Model args:\n",
      " {\n",
      "  \"dim\": 5120,\n",
      "  \"n_layers\": 48,\n",
      "  \"n_heads\": 40,\n",
      "  \"n_kv_heads\": 8,\n",
      "  \"head_dim\": null,\n",
      "  \"vocab_size\": 202048,\n",
      "  \"multiple_of\": 2048,\n",
      "  \"ffn_dim_multiplier\": 1.2,\n",
      "  \"ffn_exp\": 4.0,\n",
      "  \"norm_eps\": 0.00001,\n",
      "  \"attention_chunk_size\": 8192,\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"use_scaled_rope\": true,\n",
      "  \"rope_scaling_factor\": 16.0,\n",
      "  \"rope_high_freq_factor\": 1.0,\n",
      "  \"nope_layer_interval\": 4,\n",
      "  \"use_qk_norm\": true,\n",
      "  \"attn_temperature_tuning\": false,\n",
      "  \"floor_scale\": 8192.0,\n",
      "  \"attn_scale\": 0.1,\n",
      "  \"vision_args\": {\n",
      "    \"image_size\": {\n",
      "      \"height\": 336,\n",
      "      \"width\": 336\n",
      "    },\n",
      "    \"patch_size\": {\n",
      "      \"height\": 14,\n",
      "      \"width\": 14\n",
      "    },\n",
      "    \"dim\": 1408,\n",
      "    \"n_layers\": 34,\n",
      "    \"n_heads\": 16,\n",
      "    \"mlp_ratio\": 4.0,\n",
      "    \"output_dim\": 4096,\n",
      "    \"pixel_shuffle_ratio\": 0.5\n",
      "  },\n",
      "  \"moe_args\": {\n",
      "    \"num_experts\": 16,\n",
      "    \"capacity_factor\": 1.0,\n",
      "    \"auto_scale_F\": true,\n",
      "    \"top_k\": 1,\n",
      "    \"interleave_moe_layer_step\": 1\n",
      "  },\n",
      "  \"quantization_args\": null,\n",
      "  \"lora_args\": null,\n",
      "  \"max_batch_size\": 1,\n",
      "  \"max_seq_len\": 1024\n",
      "}\n",
      "Loading checkpoint shards:\n",
      "[PosixPath('res/llms/Llama-4-Scout-17B-16E/consolidated.00.pth')\n",
      " PosixPath('res/llms/Llama-4-Scout-17B-16E/consolidated.01.pth')\n",
      " PosixPath('res/llms/Llama-4-Scout-17B-16E/consolidated.02.pth')\n",
      " PosixPath('res/llms/Llama-4-Scout-17B-16E/consolidated.03.pth')\n",
      " PosixPath('res/llms/Llama-4-Scout-17B-16E/consolidated.04.pth')\n",
      " PosixPath('res/llms/Llama-4-Scout-17B-16E/consolidated.05.pth')\n",
      " PosixPath('res/llms/Llama-4-Scout-17B-16E/consolidated.06.pth')\n",
      " PosixPath('res/llms/Llama-4-Scout-17B-16E/consolidated.07.pth')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shining/miniforge3/envs/SenSem/lib/python3.11/site-packages/torch/__init__.py:1240: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:436.)\n",
      "  _C._set_default_tensor_type(t)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resharding 8 state dicts from MP size 8 to MP size 1\n"
     ]
    }
   ],
   "source": [
    "generator = Llama4.build(\n",
    "    checkpoint_dir,\n",
    "    max_seq_len=max_seq_len,\n",
    "    max_batch_size=max_batch_size,\n",
    "    world_size=world_size,\n",
    "    quantization_mode=quantization_mode,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211852c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bbadc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SenSem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
